---
title: "Demis Hassabis：通往 AGI 的科学方法、风险边界与未来12个月的关键突破"
date: "2025-12-07"
description: "Demis Hassabis 深度复盘 Google AI 十五年的演进历程：从 Disbelief 系统到 Transformer 架构，再到 Gemini 的多模态突破，揭示算力、算法与规模化如何重塑人工智能。"
category: "video-summary"
tags: ["Google DeepMind", "Demis Hassabis", "Gemini", "Transformer", "TPU", "Large Language Models", "AI Safety", "AGI"]
---

> **引用来源**：本文内容整理自 Google DeepMind 首席科学家 Demis Hassabis 关于人工智能发展历史与 Gemini 模型技术演进的主题分享。[Axios: Demis Hassabis 谈重要的人工智能趋势](https://www.youtube.com/watch?v=tDSDR7QILLg)

# Demis Hassabis：通往 AGI 的科学方法、风险边界与未来12个月的关键突破  
*——读 DeepMind CEO 接受 Axios 访谈有感*

谷歌 DeepMind 联合创始人兼 CEO **Demis Hassabis**，长期被视为全球人工智能领域最具远见的领导者之一。最近，他在接受 Axios 联合创始人 Mike Allen 的采访时，从个人科学方法到 AI 技术前沿、从 AGI 的时间线到全球竞争格局，为我们提供了一次罕见而深度的思想展示。

本文将对访谈内容进行总结、技术拆解与个人评价，希望帮助你更系统地理解当下全球 AI 的真实进展与未来的关键方向。

---

## 01. 科学家的思维方式：Demis 的核心方法论

### **1. 科学家身份高于管理者**  
Hassabis 多次强调：

> “我首先是一名科学家，其次才是企业家。”

他将科学方法论——试验、验证、更新假设——应用到生活和组织管理中。他认为科学方法是现代文明的基石，是推动技术前进的最可靠方式。

### **2. 平台与影响力**  
访谈中虽提到“诺贝尔奖级”的赞誉（更多是修辞），但 Hassabis 公认拥有巨大科学影响力，这使他能够在 AI 安全、负责任使用等议题上拥有全球性发声平台。

### **3. DeepMind 的核心竞争力：三位一体模型**  
Hassabis 将 DeepMind 的优势归结为：

- 世界级研究能力  
- 世界级工程能力  
- 世界级基础设施（谷歌算力）

而这些能力共同构成了 DeepMind 能持续产出 AlphaGo、AlphaFold、Gemini 等突破式成果的底层基础。

---

## 02. AI 的未来12个月：三大关键突破方向

当被问及未来一年 AI 会发生什么变化时，Hassabis 的回答极具前瞻性。

### **1. 多模态融合（Multimodal）全面开花**

不仅仅是图文，而是：

- 图像  
- 视频  
- 文本  
- 音频  

真正融为一个统一的模型架构。

Hassabis 特别强调：  
**模型对视频、尤其是对 YouTube 的理解能力被严重低估。**

### **2. 世界模型（World Models）走向实用**

以 Genie 3 为例，视频模型已经能生成可交互的动态环境，让用户“进入”场景中探索。  
这是迈向 AGI 的关键路径之一：**模型不再只是观察世界，而是模拟世界。**

### **3. Agent 智能体接近“可完成整项任务”**

Hassabis 认为，未来12个月智能体（Agent）将在以下方面迎来突破：

- 能分解任务  
- 执行更连贯  
- 错误率显著降低  
- 开始具备完成整条任务链的能力  

这标志着 AI 将从“回答问题”走向真正可委派的助理式智能。

---

## 03. AGI 时间表：5–10 年 + 一到两个关键科研突破

当谈到 AGI 时间线时，Hassabis 给出了罕见的明确说法：

> “我们还没有实现 AGI，但它不远了。”

他的预测是 **5~10 年内** 有望出现 AGI。

但他强调：

- 单纯扩大现有 LLM 规模不足以实现 AGI  
- 还需要至少 **一到两次类似 Transformer 或 AlphaGo 的基础科学级突破**  

可能会出现在推理、记忆、世界模型等方向。

---

## 04. AI 风险边界：灾难概率为“非零”  

Hassabis 对 AI 风险的表达极为冷静且坦诚。

### **潜在危险包括：**
1. 恶意行为者利用 AI 生成新型病原体  
2. AI 被用于网络攻击（他认为“几乎已经发生”）  
3. 高度自主的智能体偏离人类目标  
4. 出现“与人类利益冲突的自我利益”  

> 他明确指出：灾难性风险的概率是 **非零**。

这是目前为数不多的来自顶级 AI 科学家的公开提醒。

---

## 05. 全球竞争格局：美国领先，但仅领先“几个月”

关于中美 AI 竞争，Hassabis 的判断非常清醒。

### **美国的优势：**
- 算法创新  
- 人才密度  
- 规模化工程能力  
- TPU 等基础设施  

### **但领先幅度正在缩小：**
> “这不是几年，而是几个月的领先。”

在 AGI 的竞赛里，时间差正在迅速收窄。

---

## 06. 为什么谷歌最终转向 LLM：科学证据推动的战略决策

Hassabis 回顾了 DeepMind 在 2017–2018 年的关键转折。

当数据规模扩展揭示出 LLM 的巨大潜力时，DeepMind 逐步从原创多路径研究（如认知架构、强化学习）转向：

> **将更多资源投入到 LLM 的 Scaling Law 路线。**

这是科学证据驱动的战略调整，也是 Gemini 系列得以诞生的基础。

---

## 07. 人类适应性：游戏、训练与智能的未来

作为少年国际象棋天才、游戏设计者和 AI 科学家，Hassabis 多次强调：

> “游戏是训练心智最好的方式。”

因为它提供了一个可模拟、可重复试验的环境。

在社会层面，他认为：

> “这场技术革命比工业革命大十倍，快十倍。”

但同时相信：

> “人类大脑是通用智能唯一的证明，我们会适应这场变化。”

---

## 结语：一场阅读未来 AI 十年的“指南针级”访谈

### **优点：**
- 提供清晰的未来技术路线（多模态、世界模型、Agent）  
- 对 AGI 的判断罕见地明确而审慎  
- 深刻分析中美竞争格局  
- 对风险的评估坦诚、不回避  
- 以科学方法作为判断依据  

### **局限：**
- 作为谷歌高层，他对 AI 安全策略仍以宏观原则为主  
- 对监管细节和产品风险措施未作展开  

### **推荐指数：⭐⭐⭐⭐⭐（强烈推荐）**

这是理解全球顶尖 AI 实验室战略、技术走向与 AGI 未来不可或缺的一次访谈。

---

